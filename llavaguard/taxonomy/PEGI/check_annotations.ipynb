{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories, get_content_categories_with_numbers, policy_graph\n",
    "from PIL import Image\n",
    "from llavaguard.taxonomy.policy_config import local_image_dirs, local_data_dir\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_policy_intro, policy_graph_to_text\n",
    "import random\n",
    "\n",
    "\n",
    "im_paths = glob.glob(local_image_dirs['smid'] + '/*.jpg') + glob.glob(local_image_dirs['crawled'] + '/*/*.jpg') + glob.glob(local_image_dirs['synthetic'] + '/*/*.jpg')\n",
    "random.seed(42)\n",
    "# Select 50 random elements from im_paths\n",
    "im_paths = random.sample(im_paths, 2000)\n",
    "im_paths[0]\n",
    "\n",
    "categories_with_numbers = get_content_categories_with_numbers(policy_graph)\n",
    "categories = get_content_categories(policy_graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only display with explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from itertools import product\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories_with_numbers, get_majority_vote, policy_graph, remove_mutually_exclusive_categories\n",
    "# check annotations when prompted to evaluate each category separately\n",
    "models = [\"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"OpenGVLab/InternVL2-Llama3-76B\", \"OpenGVLab/InternVL2-40B\", \"OpenGVLab/InternVL2-8B\"]\n",
    "# models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"OpenGVLab/InternVL2-8B\"][:]\n",
    "teq = ['prompt_for_every_content_category', 'prompt_for_every_content_category_describe_image', 'prompt_for_every_content_category_describe_image2']\n",
    "path_1 = f\"{local_data_dir}/data/annotations/auto_generated_annotations\"\n",
    "m_1, t_1 = models[0].split('/')[1], teq[0]\n",
    "\n",
    "\n",
    "for im_path in im_paths[300:350]:\n",
    "    sample_path = im_path.split('images/')[-1].split('.jpg')[0]\n",
    "    sample_id = im_path.split('/')[-1].split('.')[0]\n",
    "    violations = {}\n",
    "    for model, t in product(models, [teq[0], teq[2]]):\n",
    "        name = model.split('/')[1]\n",
    "        if 'describe_image' in t:\n",
    "            name += ' with image description'\n",
    "        violations[name] = []\n",
    "        missing, invalid = 0, 0\n",
    "        for category in categories_with_numbers:\n",
    "            annot_path = os.path.join(path_1, model.split('/')[1], t, sample_path, f\"{category}.txt\")\n",
    "            if os.path.exists(annot_path):\n",
    "                with open(annot_path, 'r') as f:\n",
    "                    content = f.read()\n",
    "\n",
    "                    \n",
    "                    # if 'Yes' in content and 'No' in content:\n",
    "                    #     print(f\"Conflicting entry: {content}\")\n",
    "                    #     invalid += 1\n",
    "                    #     # violations[annot_name].append(f\"Invalid entry: {content}\")                    \n",
    "                    if 'Yes' in content:\n",
    "                        violations[name].append(category)\n",
    "                        # if model ==  'OpenGVLab/InternVL2-8B' and t == 'prompt_for_every_content_category_describe_image2':\n",
    "                        #     print(f\"{category}: {content}\")\n",
    "                        # if 'educational' in category.lower():\n",
    "                        #     print(f\"{model} ({category}): {content}\")\n",
    "                    elif 'No' in content or 'Not applicable' in content:\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(f\"{annot_name} invalid: {content}\")\n",
    "                        invalid += 1\n",
    "                        # violations[annot_name].append(f\"Invalid entry: {content}\")                \n",
    "            else:\n",
    "                # print(f'Missing file {p}')\n",
    "                missing += 1\n",
    "        if missing > 0:\n",
    "            violations[name].append(f\"Missing entries: {missing}\")\n",
    "        if invalid > 0:\n",
    "            violations[name].append(f\"Invalid entries: {invalid}\")\n",
    "\n",
    "\n",
    "    im = Image.open(im_path).resize((256, 256))\n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)\n",
    "    mv = get_majority_vote(violations)\n",
    "    print(f\"Majority Vote: {mv}\")\n",
    "    print(f\"Cleanded Categories: {remove_mutually_exclusive_categories(mv)}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# display old annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories_with_numbers\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph_old import policy_graph as policy_graph_old\n",
    "\n",
    "# check annotations when prompted to evaluate each category separately\n",
    "models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"lmms-lab/llama3-llava-next-8b\"]\n",
    "m_1 = models[0].split('/')[1]\n",
    "teq = ['prompt_for_every_content_category', 'prompt_for_every_content_category_describe_image', 'prompt_for_every_content_category_describe_image2'][2]\n",
    "path_1 = f\"{local_data_dir}/data/annotations/auto_generated_annotations-old\"\n",
    "samples = glob.glob(f\"{path_1}/{m_1}/{teq}/*/*\", recursive=True)\n",
    "categories = get_content_categories_with_numbers(policy_graph_old)\n",
    "print(len(samples))\n",
    "print(samples[0])\n",
    "for sample in samples[100:150]:\n",
    "    sample_path = sample.split(teq)[1]\n",
    "    sample_id = sample.split('/')[-1]\n",
    "    violations = {}\n",
    "    for model in models:\n",
    "        annot_path = sample.replace(m_1, model.split('/')[1])\n",
    "        annot_name = model.split('/')[1]\n",
    "        violations[annot_name] = []\n",
    "        missing, invalid = 0, 0\n",
    "        for category in categories:\n",
    "            category_no_number = category.split('. ')[1].strip()\n",
    "\n",
    "            p = annot_path + f\"/{category}.txt\"\n",
    "            if os.path.exists(p):\n",
    "                with open(p, 'r') as f:\n",
    "                    content = f.read()\n",
    "                    # if 'animal' in category_no_number:\n",
    "                    #     print(content)\n",
    "                    if 'Yes' in content:\n",
    "                        violations[annot_name].append(category)\n",
    "                    elif 'No' in content or 'Not applicable' in content:\n",
    "                        pass\n",
    "                    else:\n",
    "                        # print(f\"{annot_name} invalid: {content}\")\n",
    "                        invalid += 1\n",
    "                        # violations[annot_name].append(f\"Invalid entry: {content}\")                \n",
    "            else:\n",
    "                # print(f'Missing file {p}')\n",
    "                missing += 1\n",
    "        if missing > 0:\n",
    "            violations[annot_name].append(f\"Missing entries: {missing}\")\n",
    "        if invalid > 0:\n",
    "            violations[annot_name].append(f\"Invalid entries: {invalid}\")\n",
    "    im = Image.open(f\"{local_data_dir}/data/images/{sample_path}.jpg\")\n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)\n",
    "    print(f\"Majority Vote: {get_majority_vote(violations)}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Category - One prompt for all content categories\n",
    "## -> this does not work at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check annotations when prompted to evaluate all content categories in one prompt\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories\n",
    "\n",
    "\n",
    "models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"lmms-lab/llama3-llava-next-8b\"]\n",
    "path_2 =  f\"{local_data_dir}/data/annotations/auto_generated_annotations/{models[1].split('/')[1]}/prompt_for_all_content_categories\"\n",
    "samples = glob.glob(f\"{path_2}/**/*.txt\", recursive=True)\n",
    "print(\"Number of samples:\", len(samples))\n",
    "print(samples[0])\n",
    "categories = get_content_categories(policy_graph)\n",
    "\n",
    "for sample in samples[:]:\n",
    "    sample_path = sample.split(\"prompt_for_all_content_categories/\")[1].split('.txt')[0]\n",
    "    sample_id = p.split('/')[-2].split('.txt')[0]\n",
    "    violations = {}\n",
    "    for model in models:\n",
    "        violations[model] = []\n",
    "        missing = 0\n",
    "        p2 = sample.replace(path_2.split('/')[-2], model.split('/')[1])\n",
    "        if os.path.exists(p):\n",
    "            with open(p2, \"r\") as f:\n",
    "                content = f.read()\n",
    "                # violations[model].append(cats)\n",
    "                if 'None Applicable' in content or 'No' in content:\n",
    "                    pass\n",
    "                else:\n",
    "                    violations[model].append(content)\n",
    "                    # for c in categories:\n",
    "                    #     if c.strip() in content:\n",
    "                    #         violations[model].append(c.strip())\n",
    "        else:\n",
    "            violations[model].append(\"Missing entries\")\n",
    "    im = Image.open(f\"{local_data_dir}/data/images/{sample_path}.jpg\")\n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety Category - One prompt for all safety categories\n",
    "## -> this also works very bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check annotations when prompted to evaluate all safety categories in one prompt\n",
    "models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"lmms-lab/llama3-llava-next-8b\"]\n",
    "path_3 =  f\"{local_data_dir}/data/annotations/auto_generated_annotations/{models[1].split('/')[1]}/prompt_for_all_safety_categories/\"\n",
    "samples = glob.glob(f\"{path_3}/**/*.txt\", recursive=True)\n",
    "categories = get_content_categories(policy_graph)\n",
    "\n",
    "for sample in samples[:50]:\n",
    "    sample_path = sample.split(\"prompt_for_all_safety_categories/\")[1].split('.txt')[0]\n",
    "    sample_id = path_3.split('/')[-2].split('.txt')[0]\n",
    "    violations = {}\n",
    "    for model in models:\n",
    "        violations[model] = []\n",
    "        missing = 0\n",
    "        p2 = sample.replace(path_2.split('/')[-2], model.split('/')[1])\n",
    "        if os.path.exists(p):\n",
    "            with open(p2, \"r\") as content:\n",
    "                content = content.read()\n",
    "                violations[model] = content\n",
    "\n",
    "                # if 'None Applicable' in content or 'No' in content:\n",
    "                #     pass\n",
    "                # else:\n",
    "                #     for c in categories:\n",
    "                #         if c.strip() in content:\n",
    "                #             violations[model].append(c.strip())\n",
    "        else:\n",
    "            violations[model].append(\"Missing entries\")\n",
    "    im = Image.open(f\"{local_data_dir}/data/images/{sample_path}.jpg\")\n",
    "    \n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "im_paths = glob.glob(local_image_dirs['smid'] + '/*.jpg') + glob.glob(local_image_dirs['crawled'] + '/*/*.jpg') + glob.glob(local_image_dirs['synthetic'] + '/*/*.jpg')\n",
    "random.seed(42)\n",
    "im_paths = random.sample(im_paths, 50)\n",
    "im_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Category - One prompt for for every safety categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories_with_numbers, policy_graph\n",
    "\n",
    "safety_categories = list(policy_graph.keys())\n",
    "models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"lmms-lab/llama3-llava-next-8b\"]\n",
    "path_1 = f\"{local_data_dir}/data/annotations/auto_generated_annotations/{models[-1].split('/')[1]}/prompt_for_every_safety_categories\"\n",
    "samples = glob.glob(f\"{path_1}/*/*\", recursive=True)\n",
    "categories = get_content_categories_with_numbers(policy_graph)\n",
    "print(len(samples))\n",
    "print(samples[0])\n",
    "for sample in samples[:10]:\n",
    "    sample_path = sample.split('prompt_for_every_safety_categories')[1]\n",
    "    sample_id = sample.split('/')[-1]\n",
    "    violations = {}\n",
    "    for model in models:\n",
    "        model_path = sample.replace(path_1.split('/')[-2], model.split('/')[1])\n",
    "        violations[model] = []\n",
    "        missing = 0\n",
    "        for safety_category, graph_data in policy_graph.items():\n",
    "            p =  f\"{model_path}/{safety_category.replace(' ', '_')}.txt\"\n",
    "            if os.path.exists(p):\n",
    "                with open(p, 'r') as f:\n",
    "                    content = f.read()\n",
    "                    violations[model].append(content)\n",
    "\n",
    "                    # if 'No' in content:\n",
    "                    #     pass\n",
    "                    # else:\n",
    "                    #     violations[model].append(content)\n",
    "                \n",
    "                    # for category in graph_data.keys():\n",
    "                    #     if category in content:\n",
    "                    #         violations[model].append(category)\n",
    "            else:\n",
    "                missing += 1\n",
    "        if missing > 0:\n",
    "            violations[model].append(f\"Missing entries: {missing}\")\n",
    "    im = Image.open(f\"{local_data_dir}/data/images/{sample_path}.jpg\")\n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content category - Individual promts for every category \n",
    "## Compare with explanation to no explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from llavaguard.taxonomy.PEGI.PEGI_Graph import get_content_categories_with_numbers, policy_graph\n",
    "\n",
    "# check annotations when prompted to evaluate each category separately\n",
    "models = [\"Qwen/Qwen2-VL-7B-Instruct\", \"Qwen/Qwen2-VL-72B-Instruct\", \"lmms-lab/llava-onevision-qwen2-7b-ov\", \"lmms-lab/llava-onevision-qwen2-72b-ov\", \"lmms-lab/llama3-llava-next-8b\"]\n",
    "models = [models[0], models[2]]\n",
    "m_1 = models[0].split('/')[1]\n",
    "path_1 = f\"{local_data_dir}/data/annotations/tmp\"\n",
    "samples = glob.glob(f\"{path_1}/{m_1}/prompt_for_every_content_category/*/*\", recursive=True)\n",
    "categories = get_content_categories_with_numbers(policy_graph)\n",
    "print(len(samples))\n",
    "print(samples[0])\n",
    "for sample in samples[:50]:\n",
    "    sample_path = sample.split('prompt_for_every_content_category')[1]\n",
    "    sample_id = sample.split('/')[-1]\n",
    "    violations = {}\n",
    "    for model in models:\n",
    "        for teq in ['prompt_for_every_content_category', 'prompt_for_every_content_category_describe_image2']:\n",
    "            annot_path = sample.replace(m_1, model.split('/')[1])\n",
    "            annot_path = annot_path.replace('prompt_for_every_content_category', teq)\n",
    "            annot_name = f\"{model.split('/')[1]} w/ {teq.replace('prompt_for_every_content_category', '')}\" if 'describe_image' in annot_path else f\"{model.split('/')[1]}\"\n",
    "            violations[annot_name] = []\n",
    "            missing, invalid = 0, 0\n",
    "            for category in categories:\n",
    "                category_no_number = category.split('. ')[1].strip()\n",
    "                p = annot_path + f\"/{category}.txt\"\n",
    "                if os.path.exists(p):\n",
    "                    with open(p, 'r') as f:\n",
    "                        content = f.read()                        \n",
    "                        if 'Yes' in content:\n",
    "                            violations[annot_name].append(category)\n",
    "                            if category == '24. Highly Disturbing Content':\n",
    "                                print(content)\n",
    "                        elif 'No' in content or 'Not applicable' in content:\n",
    "                            pass\n",
    "                        else:\n",
    "                            # print(f\"{annot_name} invalid: {content}\")\n",
    "                            invalid += 1\n",
    "                            # violations[annot_name].append(f\"Invalid entry: {content}\")                \n",
    "                else:\n",
    "                    # print(f'Missing file {p}')\n",
    "                    missing += 1\n",
    "            if missing > 0:\n",
    "                violations[annot_name].append(f\"Missing entries: {missing}\")\n",
    "            if invalid > 0:\n",
    "                violations[annot_name].append(f\"Invalid entries: {invalid}\")\n",
    "    im = Image.open(f\"{local_data_dir}/data/images/{sample_path}.jpg\")\n",
    "    im.show()\n",
    "    print(f\"Image: {sample_id}\")\n",
    "    for key, value in violations.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    print(\"=====================================\"*2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
